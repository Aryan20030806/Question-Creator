{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39efdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7289921",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fd92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9851c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210fe3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\Aryan Parihar\\\\Desktop\\\\GEN-AI\\\\Projects\\\\Question creator\\\\data\\\\MIT-Review-Research-Report.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for storing all the data in a single variable\n",
    "question_gen =\"\"\n",
    "for page in data:\n",
    "    question_gen += page.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2786c7",
   "metadata": {},
   "source": [
    "# chunking operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da825377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using llm to perform chunking as we use token-based splitting\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "splitter_ques_gen = TokenTextSplitter(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    chunk_size=1000,\n",
    "   chunk_overlap=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2b88635",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_ques_gen = splitter_ques_gen.split_text(question_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfa0b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_ques_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae05b4d",
   "metadata": {},
   "source": [
    "# implementing the openAI model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6119f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm_ques_gen_pipeline = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0f0ee",
   "metadata": {},
   "source": [
    "# creating hte prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afd6a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Generate five comprehensive and thought-provoking questions based on the following context to assess understanding and critical thinking skills.\n",
    "Context:\n",
    "{text}\n",
    "Create questions suitable for an interview setting.\n",
    "Number the questions from 1 to 5.\n",
    "Questions:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a86a096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a580f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ques_gen = PromptTemplate(template=prompt_template, \n",
    "                                input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58e94ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a refined prompt template for question generation according t the additional text provided by the user\n",
    "refined_prompt_template_ques_gen = \"\"\"You are an expert question generator. Based on the following context, generate only 5 questions based on the input provided by the user into more deep knowledge and thought-provoking questions to assess understanding and critical thinking skills.\n",
    "Context: {text}\n",
    "{existing_answer}.\n",
    "Questions:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4787c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_prompt_ques_gen = PromptTemplate(template=refined_prompt_template_ques_gen,\n",
    "                                        input_variables=[\"text\", \"existing_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e02825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "286e6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How can health-care institutions ensure that AI technologies are implemented in a way that truly enhances the quality of patient care and does not replace human interaction?\n",
      "--------------------------------------------------\n",
      "2. How do health care institutions prioritize their AI budget allocation between different AI applications, such as patient flow optimization, medical imaging, and predictive analytics?\n",
      "--------------------------------------------------\n",
      "3. How do AI-enabled scheduling tools give more autonomy to patients while streamlining smarter scheduling and increasing resource capacity in healthcare settings?\n",
      "--------------------------------------------------\n",
      "4. How can AI technologies be further developed to enhance the efficiency and accuracy of medical image analysis for clinicians?\n",
      "--------------------------------------------------\n",
      "5. How can AI be integrated into healthcare ecosystems to ensure that improvements made locally can have a global impact on healthcare?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_refined_questions = []\n",
    "\n",
    "for chunk in chunks_ques_gen:\n",
    "    refined = (refined_prompt_ques_gen | llm_ques_gen_pipeline | parser).invoke({\n",
    "        \"text\": chunk,\n",
    "        \"existing_answer\": (prompt_ques_gen | llm_ques_gen_pipeline | parser).invoke({\"text\": chunk})\n",
    "    })\n",
    "    all_refined_questions.append(refined.split(\"\\n\")[0].lstrip(\"0123456789. \"))\n",
    "\n",
    "for i, q in enumerate(all_refined_questions, 1):\n",
    "    print(f\"{i}. {q}\")\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c287c4a",
   "metadata": {},
   "source": [
    "# storing to vector embedding for ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "556128cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25d288b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ada09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing to vector embedding for ans\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore_ques_gen = FAISS.from_texts(\n",
    "    all_refined_questions,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the llm for answer generation\n",
    "llm_ans_gen = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "   temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1cf4081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How can health-care institutions ensure that AI technologies are implemented in a way that truly enhances the quality of patient care and does not replace human interaction?',\n",
       " 'How do health care institutions prioritize their AI budget allocation between different AI applications, such as patient flow optimization, medical imaging, and predictive analytics?',\n",
       " 'How do AI-enabled scheduling tools give more autonomy to patients while streamlining smarter scheduling and increasing resource capacity in healthcare settings?',\n",
       " 'How can AI technologies be further developed to enhance the efficiency and accuracy of medical image analysis for clinicians?',\n",
       " 'How can AI be integrated into healthcare ecosystems to ensure that improvements made locally can have a global impact on healthcare?']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_refined_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How can health-care institutions ensure that AI technologies are implemented in a way that truly enhances the quality of patient care and does not replace human interaction?\n",
      "A: content='Health-care institutions can ensure that AI technologies are implemented in a way that enhances patient care and maintains human interaction by carefully considering ethical considerations, leveraging AI to address disparities in access to healthcare, utilizing AI for preventive care and early detection of health issues, and ensuring that AI complements the skills and expertise of medical professionals rather than replacing them.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 196, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUYmhVbO2NWs3XDDEWo3KlnK6RcNP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--06c194b5-f048-425e-863e-5c11667b498e-0' usage_metadata={'input_tokens': 196, 'output_tokens': 67, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "--------------------------------------------------\n",
      "Q: How do health care institutions prioritize their AI budget allocation between different AI applications, such as patient flow optimization, medical imaging, and predictive analytics?\n",
      "A: content='Health care institutions prioritize their AI budget allocation based on the specific needs and goals of the organization, considering factors such as improving patient care, operational efficiency, and cost-effectiveness.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 217, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUYmjlOWwZ0F5OUmTJzL2rvTYuAbn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--c44e108a-cb6d-4944-86c1-97782fd4e70d-0' usage_metadata={'input_tokens': 217, 'output_tokens': 35, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "--------------------------------------------------\n",
      "Q: How do AI-enabled scheduling tools give more autonomy to patients while streamlining smarter scheduling and increasing resource capacity in healthcare settings?\n",
      "A: content='AI-enabled scheduling tools allow patients to schedule appointments at their convenience, reducing wait times and giving them more control over their healthcare. This streamlines scheduling processes, increases resource capacity, and ultimately improves efficiency in healthcare settings.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 167, 'total_tokens': 210, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUYmkKh7paKwR39WwBMhx5bXS4riy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--938f7756-1511-4603-92ad-65e798ff710e-0' usage_metadata={'input_tokens': 167, 'output_tokens': 43, 'total_tokens': 210, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "--------------------------------------------------\n",
      "Q: How can AI technologies be further developed to enhance the efficiency and accuracy of medical image analysis for clinicians?\n",
      "A: content='AI technologies can be further developed by improving algorithms for image analysis, integrating more advanced machine learning techniques, and ensuring seamless integration with existing healthcare systems to enhance efficiency and accuracy for clinicians.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 199, 'total_tokens': 235, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUYmmqmbfucaSgRoPMAJXX9rdfXKH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--719b046c-cf0e-4232-b068-bfd5e68db182-0' usage_metadata={'input_tokens': 199, 'output_tokens': 36, 'total_tokens': 235, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "--------------------------------------------------\n",
      "Q: How can AI be integrated into healthcare ecosystems to ensure that improvements made locally can have a global impact on healthcare?\n",
      "A: content='AI can be integrated into healthcare ecosystems by ensuring that advancements made locally are shared and implemented globally through collaboration, data sharing, and standardized protocols.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 183, 'total_tokens': 211, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUYmpeA63dabkJgUnZ49zOwQdSV2H', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--a2c20769-8433-489f-8bf6-76ad4467f271-0' usage_metadata={'input_tokens': 183, 'output_tokens': 28, 'total_tokens': 211, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for question in all_refined_questions:\n",
    "    results = vectorstore_ques_gen.similarity_search(question, k=1)\n",
    "    retrieved_text = results[0].page_content if results else \"No relevant content found\"\n",
    "    prompt = f\"Based on the following text, answer the question in a concise and readable way:\\n\\nText: {retrieved_text}\\n\\nQuestion: {question}\"\n",
    "    refined_answer = llm_ques_gen_pipeline.invoke(prompt)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {refined_answer}\")\n",
    "    print(\"-\" * 50)\n",
    "    with open(\"generated_questions_and_answers.txt\", \"a\", encoding=\"utf-8\") as f: # storing in file\n",
    "        f.write(f\"Question: {question}\\n\")\n",
    "        f.write(f\"Answer: {refined_answer}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
